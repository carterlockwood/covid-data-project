{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries that are part of the Python standard library\n",
    "import gzip\n",
    "import itertools\n",
    "import json\n",
    "import pathlib\n",
    "import string\n",
    "import time\n",
    "\n",
    "# Third-party packages\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_nltk_downloader = False\n",
    "\n",
    "if run_nltk_downloader:\n",
    "    nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data includes 3157730 observations.\n"
     ]
    }
   ],
   "source": [
    "# create a pathlib.Path object for the data\n",
    "raw_data_filepath = pathlib.Path('relevant_data_location.json')\n",
    "\n",
    "# open the data filepath\n",
    "with open(raw_data_filepath, 'r') as fp:\n",
    "    tweet_data = json.load(fp)\n",
    "    \n",
    "print(f'The data includes {len(tweet_data)} observations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(0)\n",
    "#sample_size = 5000\n",
    "#excerpt = np.random.choice(tweet_data, size=sample_size, replace=False,)\n",
    "#excerpt=tweet_data[0:10000]\n",
    "column_names = [\n",
    "    'Datetime',\n",
    "    'Username',\n",
    "    'User',\n",
    "    'Loc1',\n",
    "    'Loc2',\n",
    "    'Language',\n",
    "    'Text',\n",
    "]\n",
    "tweet_df = pd.DataFrame(tweet_data, columns = column_names)\n",
    "#exc_tweet_df = pd.DataFrame(excerpt, columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this block is for cleaning tokens. Will be useful once we get into topic modeling\n",
    "user_defined_stop_words = ['..', '...', 'get', '\\u200d', '’', '“', '”']\n",
    "\n",
    "my_mwe_tuples = [\n",
    "    ('u', '.', 's', '.'),\n",
    "    ('covid', '-', '19'),\n",
    "]\n",
    "\n",
    "i = nltk.corpus.stopwords.words('english')\n",
    "j = list(string.punctuation) + user_defined_stop_words\n",
    "stopwords = set(i).union(j)\n",
    "\n",
    "tknzr = nltk.tokenize.TweetTokenizer()\n",
    "mwe_tknzr = nltk.tokenize.MWETokenizer()\n",
    "mwe_tknzr.add_mwe(my_mwe_tuples)\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "\n",
    "def create_tok(x):\n",
    "    tokens = tknzr.tokenize(x.lower())\n",
    "    tokens = mwe_tknzr.tokenize(tokens)\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    tokens = [token for token in tokens if token not in set(stopwords)]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exc_tweet_df['Tokens'] = exc_tweet_df['Text'].apply(create_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter to get just tweets from AL use on 'tweet_data' for full dataset\n",
    "alabama_df = tweet_df.loc[tweet_df['Loc2'].str.contains(\"AL | Alabama | al | alabama\"),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert Datetime column to actual datetime\n",
    "tweet_df.loc[:,'Datetime'] = pd.to_datetime(tweet_df['Datetime'], \n",
    "                                      format = '%a %b %d %H:%M:%S %z %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert Datetime column to actual datetime\n",
    "alabama_df.loc[:,'Datetime'] = pd.to_datetime(alabama_df['Datetime'], \n",
    "                                      format = '%a %b %d %H:%M:%S %z %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten tokens column. Not recommended for big dataframe\n",
    "real_toks = [val for key, val in exc_tweet_df[\"Tokens\"].iteritems()]\n",
    "#had to get a flat list of all tokens; might be an easier way\n",
    "flat_tok_list = [item for sublist in real_toks for item in sublist]\n",
    "freq_dist = nltk.FreqDist(iter(flat_tok_list))\n",
    "freq_dist.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "sent_scores = []\n",
    "for x in range(10000):\n",
    "    sent_scores.append(analyser.polarity_scores(exc_tweet_df.loc[x, 'Text'])['compound'])\n",
    "    \n",
    "exc_tweet_df.loc[4, 'Text']\n",
    "exc_tweet_df[\"CSP\"] = sent_scores\n",
    "exc_tweet_df.head()\n",
    "exc_tweet_df.to_csv(r'sample_tweet_frame.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new = tweet_df.sample(n=10000)\\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\\nanalyser = SentimentIntensityAnalyzer()\\n#sent_scores = []\\nx=0\\nfor index, row in new.iterrows():\\n    print(row[\"User\"] + \" \" + str(analyser.polarity_scores(row[\\'Text\\'])[\\'compound\\']))\\n    #sent_scores.append(analyser.polarity_scores(row[\\'Text\\'])[\\'compound\\'])\\n    x = x + 1\\n    if(x > 50):\\n        break\\nnew[\"CSP\"] = sent_scores\\nnew.to_csv(r\\'sample_tweet_frame.csv\\', index = False)'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''new = tweet_df.sample(n=10000)\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "#sent_scores = []\n",
    "x=0\n",
    "for index, row in new.iterrows():\n",
    "    print(row[\"User\"] + \" \" + str(analyser.polarity_scores(row['Text'])['compound']))\n",
    "    #sent_scores.append(analyser.polarity_scores(row['Text'])['compound'])\n",
    "    x = x + 1\n",
    "    if(x > 50):\n",
    "        break\n",
    "new[\"CSP\"] = sent_scores\n",
    "new.to_csv(r'sample_tweet_frame.csv', index = False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "sent_scores = []\n",
    "for index, row in alabama_df.iterrows():\n",
    "    #print(row[\"User\"] + \" \" + str(analyser.polarity_scores(row['Text'])['compound']))\n",
    "    sent_scores.append(analyser.polarity_scores(row['Text'])['compound'])\n",
    "    \n",
    "alabama_df = pd.DataFrame(data=alabama_df)\n",
    "alabama_df[\"CSP\"] = sent_scores\n",
    "alabama_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "alabama_df.to_csv(r'alabama_tweet_frame.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                        215261\n",
       "unique                       210373\n",
       "top       2020-06-20 20:46:41+00:00\n",
       "freq                              5\n",
       "first     2020-03-27 23:20:45+00:00\n",
       "last      2020-10-19 18:13:07+00:00\n",
       "Name: Datetime, dtype: object"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alabama_df[\"Datetime\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>AvgCSP</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>State</th>\n",
       "      <th>TweetCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Choctaw County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clay County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cleburne County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coosa County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            County  AvgCSP    FIPS State  TweetCount\n",
       "0   Choctaw County     NaN  1023.0    AL           0\n",
       "1      Clay County     NaN  1027.0    AL           0\n",
       "2  Cleburne County     NaN  1029.0    AL           0\n",
       "3     Coosa County     NaN  1037.0    AL           0\n",
       "4           County     NaN     NaN   NaN           0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fips = pd.read_csv('alabama_csp_fips.csv')\n",
    "fips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>AvgCSP</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>State</th>\n",
       "      <th>TweetCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Choctaw County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clay County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cleburne County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coosa County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lamar County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sumter County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Washington County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wilcox County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Crenshaw County</td>\n",
       "      <td>-0.400700</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chambers County</td>\n",
       "      <td>0.075658</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Randolph County</td>\n",
       "      <td>0.080771</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Clarke County</td>\n",
       "      <td>0.091160</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Colbert County</td>\n",
       "      <td>0.115462</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>1925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DeKalb County</td>\n",
       "      <td>0.130019</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               County    AvgCSP    FIPS State  TweetCount\n",
       "0      Choctaw County       NaN  1023.0    AL           0\n",
       "1         Clay County       NaN  1027.0    AL           0\n",
       "2     Cleburne County       NaN  1029.0    AL           0\n",
       "3        Coosa County       NaN  1037.0    AL           0\n",
       "4              County       NaN     NaN   NaN           0\n",
       "5        Lamar County       NaN  1075.0    AL           0\n",
       "6       Sumter County       NaN  1119.0    AL           0\n",
       "7   Washington County       NaN  1129.0    AL           0\n",
       "8       Wilcox County       NaN  1131.0    AL           0\n",
       "9     Crenshaw County -0.400700  1041.0    AL           1\n",
       "10    Chambers County  0.075658  1017.0    AL         749\n",
       "11    Randolph County  0.080771  1111.0    AL          84\n",
       "12      Clarke County  0.091160  1025.0    AL         998\n",
       "13     Colbert County  0.115462  1033.0    AL        1925\n",
       "14      DeKalb County  0.130019  1049.0   NaN         212"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fips.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips = fips[fips['FIPS'].notna()]\n",
    "fips.FIPS = fips.FIPS.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nThe create_choropleth figure factory requires the plotly-geo package.\nInstall using pip with:\n\n$ pip install plotly-geo\n\nOr, install using conda with\n\n$ conda install -c plotly plotly-geo\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-633edb49feb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0masp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtitle_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'USA by Unemployment %'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mlegend_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'% unemployed'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/plotly/figure_factory/_county_choropleth.py\u001b[0m in \u001b[0;36mcreate_choropleth\u001b[0;34m(fips, values, scope, binning_endpoints, colorscale, order, simplify_county, simplify_state, asp, show_hover, show_state_data, state_outline, county_outline, centroid_marker, round_legend_values, exponent_format, legend_title, **layout_options)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;31m$\u001b[0m \u001b[0mconda\u001b[0m \u001b[0minstall\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mc\u001b[0m \u001b[0mplotly\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgeo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m \"\"\"\n\u001b[0m\u001b[1;32m    616\u001b[0m         )\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: \nThe create_choropleth figure factory requires the plotly-geo package.\nInstall using pip with:\n\n$ pip install plotly-geo\n\nOr, install using conda with\n\n$ conda install -c plotly plotly-geo\n"
     ]
    }
   ],
   "source": [
    "import plotly.figure_factory as ff\n",
    "import plotly\n",
    "\n",
    "df_sample = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/laucnty16.csv')\n",
    "df_sample['State FIPS Code'] = df_sample['State FIPS Code'].apply(lambda x: str(x).zfill(2))\n",
    "df_sample['County FIPS Code'] = df_sample['County FIPS Code'].apply(lambda x: str(x).zfill(3))\n",
    "df_sample['FIPS'] = df_sample['State FIPS Code'] + df_sample['County FIPS Code']\n",
    "\n",
    "colorscale = [\"#f7fbff\", \"#ebf3fb\", \"#deebf7\", \"#d2e3f3\", \"#c6dbef\", \"#b3d2e9\", \"#9ecae1\",\n",
    "    \"#85bcdb\", \"#6baed6\", \"#57a0ce\", \"#4292c6\", \"#3082be\", \"#2171b5\", \"#1361a9\",\n",
    "    \"#08519c\", \"#0b4083\", \"#08306b\"\n",
    "]\n",
    "endpts = list(np.linspace(1, 12, len(colorscale) - 1))\n",
    "fips = df_sample['FIPS'].tolist()\n",
    "values = df_sample['Unemployment Rate (%)'].tolist()\n",
    "\n",
    "\n",
    "fig = ff.create_choropleth(\n",
    "    fips=fips, values=values, scope=['usa'],\n",
    "    binning_endpoints=endpts, colorscale=colorscale,\n",
    "    show_state_data=False,\n",
    "    show_hover=True,\n",
    "    asp = 2.9,\n",
    "    title_text = 'USA by Unemployment %',\n",
    "    legend_title = '% unemployed'\n",
    ")\n",
    "fig.layout.template = None\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'geo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-d29e3b762de2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Check your version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshapely\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplotly\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgeo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'geo' is not defined"
     ]
    }
   ],
   "source": [
    "import geopandas\n",
    "import shapely\n",
    "import plotly\n",
    "from plotly.figure_factory._county_choropleth import create_choropleth\n",
    "import xlrd\n",
    "# Check your version\n",
    "print(plotly.__version__, geopandas.__version__,shapely.__version__,plotly-geo.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
